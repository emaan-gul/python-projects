{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtOioArOLbLc"
      },
      "outputs": [],
      "source": [
        "#import the libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bz6peKBMNXT"
      },
      "outputs": [],
      "source": [
        "#load housing dataset\n",
        "dataset = pd.read_csv('/content/Housing.csv')\n",
        "df = dataset.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrDU4Jz0MQke"
      },
      "outputs": [],
      "source": [
        "# Display the sample dataset\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEnNSxJMOgUX"
      },
      "outputs": [],
      "source": [
        "# Check the shape of the dataset\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoeCBhRLMfZc"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2Usuk4gMpDV"
      },
      "outputs": [],
      "source": [
        "# Replace missing 'furnishin gstatus' with 'Unknown'\n",
        "df['furnishin gstatus'].fillna('Unknown', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58HngNy5NeUy"
      },
      "outputs": [],
      "source": [
        "# Fill missing 'price' values with median\n",
        "median_price = df['price'].median()\n",
        "df['price'].fillna(median_price, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGu8RDn2Nod3"
      },
      "outputs": [],
      "source": [
        "# Fill missing 'mainroad' values with mode\n",
        "mode_mainroad = df['mainroad'].mode()[0]\n",
        "df['mainroad'].fillna(mode_mainroad, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tl-CaGaNvFt"
      },
      "outputs": [],
      "source": [
        "# Drop rows of other missing values\n",
        "mode_mainroad = df['mainroad'].mode()[0]\n",
        "df['mainroad'].fillna(mode_mainroad, inplace=True)\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdEoMDxDN96i"
      },
      "outputs": [],
      "source": [
        "# Check for duplicates\n",
        "duplicate_rows = df[df.duplicated()]\n",
        "print(duplicate_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVlDi0kGOBPr"
      },
      "outputs": [],
      "source": [
        "# Drop duplicates\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwzQ29PSOEBs"
      },
      "outputs": [],
      "source": [
        "# CONVERSION OF TEXT TO NUMERIC (All the \"yes\" in the dataset should be converted into \"1\" and all the \"No\" should be converted into \"0\")\n",
        "df.replace({'Yes': 1, 'No': 0}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N-AxeW5Tpee"
      },
      "source": [
        "**Explain your Code here:**\n",
        "\n",
        "1. executed the python built in libraries so we can use the functions of the library in our data set.\n",
        "2. uploaded the csv file into collab and made copy of it. \n",
        "3. displayed the dataset.\n",
        "4. found information of null values.\n",
        "5. used isnull function to find null values , thier position and count.\n",
        "6. row of \"furnishingstatus\" data got replaced with \"unknown\"  by fillin function and used inplace=true so the row doesn't get deleted.\n",
        "7. using median filled the missing dataset.\n",
        "8. using mode filled the missing mainroad.\n",
        "9. other rows were dropped.\n",
        "10. dropped the duplicate dataset.\n",
        "11. replaced \"Yes\" with 1 and \"No\" with 0 using replace fucntion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZxKtARhP7fv",
        "outputId": "26d52e1e-dca1-495e-b157-c864de3ec83d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Tokenization', 'is', 'the', 'process', 'of', 'breaking', 'down', 'text', 'into', 'smaller', 'components', 'such', 'as', 'words', 'or', 'sentences.', 'Tokenization', 'helps', 'in', 'preparing', 'text', 'data', 'for', 'further', 'analysis.']\n",
            "Tokenization: 2\n",
            "is: 1\n",
            "the: 1\n",
            "process: 1\n",
            "of: 1\n",
            "breaking: 1\n",
            "down: 1\n",
            "text: 2\n",
            "into: 1\n",
            "smaller: 1\n",
            "components: 1\n",
            "such: 1\n",
            "as: 1\n",
            "words: 1\n",
            "or: 1\n",
            "sentences.: 1\n",
            "helps: 1\n",
            "in: 1\n",
            "preparing: 1\n",
            "data: 1\n",
            "for: 1\n",
            "further: 1\n",
            "analysis.: 1\n"
          ]
        }
      ],
      "source": [
        "# Sample text for tokenization\n",
        "text = \"Tokenization is the process of breaking down text into smaller components such as words or sentences. Tokenization helps in preparing text data for further analysis.\"\n",
        "\n",
        "# Tokenize (Split) the text into words\n",
        "words = text.split()\n",
        "\n",
        "# Print token\n",
        "print(words)\n",
        "\n",
        "# Count the frequency of each word (avoid to use library)\n",
        "words_frequency = {}\n",
        "for word in words:\n",
        "  if word in words_frequency:\n",
        "    words_frequency[word] += 1\n",
        "  else:\n",
        "    words_frequency[word] = 1\n",
        "\n",
        "# Print the frequency of each word\n",
        "for word, freq in words_frequency.items():\n",
        "    print(f\"{word}: {freq}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZajAKS50Qi0T"
      },
      "source": [
        "**Explain your Code here**\n",
        "\n",
        "1. text splitted in words.\n",
        "\n",
        "2. print them.\n",
        "\n",
        "3. empty dictionary was initialized to store words frequency, used for loop to count the words already used then incremented the count +1.\n",
        "\n",
        "4. frequencies got printed.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
